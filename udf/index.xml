<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>User Defined Functions | Yauaa - Yet Another UserAgent Analyzer</title><link>/udf/index.html</link><description>Several external computation systems support the concept of a User Defined Function (UDF). A UDF is simply a way of making functionality (in this case the analysis of useragents) available in such a system.
For several systems (tools used within bol.com (where I work)) I have written such a UDF which are all part of this project.
Apache Beam Apache Beam SQL Apache Drill Apache Flink Apache Flink Table/SQL Apache Hive Apache Nifi Apache Pig Commandline usage Elastic LogStash Elastic Search LogParser Snowflake Snowplow Trino</description><generator>Hugo</generator><language>en-us</language><atom:link href="/udf/index.xml" rel="self" type="application/rss+xml"/><item><title>Apache Beam</title><link>/udf/apache-beam/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/apache-beam/index.html</guid><description>Introduction This is a User Defined Function for Apache Beam
Getting the UDF You can get the prebuilt UDF from maven central.
If you use a maven based project simply add this dependency to your project.
&lt;dependency> &lt;groupId>nl.basjes.parse.useragent&lt;/groupId> &lt;artifactId>yauaa-beam&lt;/artifactId> &lt;version>7.31.0&lt;/version> &lt;/dependency> Usage Assume you have a PCollection with your records. In most cases I see (clickstream data) these records (In this example this class is called “TestRecord”) contain the useragent string in a field and the parsed results must be added to these fields.</description></item><item><title>Apache Beam SQL</title><link>/udf/apache-beam-sql/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/apache-beam-sql/index.html</guid><description>Introduction This is a User Defined Function for Apache Beam SQL.
Getting the UDF You can get the prebuilt UDF from maven central.
If you use a maven based project simply add this dependency to your project.
&lt;dependency> &lt;groupId>nl.basjes.parse.useragent&lt;/groupId> &lt;artifactId>yauaa-beam-sql&lt;/artifactId> &lt;version>7.31.0&lt;/version> &lt;/dependency> Available functions Getting a single value To get a single value from the parse result use this one:
ParseUserAgentField(userAgent, 'DeviceClass') AS deviceClassField to give
Phone Getting several values as a Map (requires Apache Beam 2.30.0 or newer) You can ask for all fields and return the full map with all of them in there.</description></item><item><title>Apache Drill</title><link>/udf/apache-drill/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/apache-drill/index.html</guid><description>Introduction This is UDF for Apache Drill. This function was originally created by Charles S. Givre and was imported into the main Yauaa project to ensure users would have a prebuilt and up-to-date version available.
This function is now also packaged as part of Apache Drill itself: documentation.
Notable changes With Yauaa 7.0.0
the code for this UDF has been copied back from the Drill project to ensure it keeps working as expected. the parse_user_agent_field has been removed and parse_user_agent supports the same input/output now. Usage I have copied/implemented the functions</description></item><item><title>Apache Flink</title><link>/udf/apache-flink/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/apache-flink/index.html</guid><description>Introduction This is a User Defined Function for Apache Flink
Getting the UDF You can get the prebuilt UDF from maven central.
If you use a maven based project simply add this dependency to your project.
&lt;dependency> &lt;groupId>nl.basjes.parse.useragent&lt;/groupId> &lt;artifactId>yauaa-flink&lt;/artifactId> &lt;version>7.31.0&lt;/version> &lt;/dependency> Usage Assume you have a DataSet or DataStream with your records. In most cases I see (clickstream data) these records (In this example this class is called “TestRecord”) contain the useragent string in a field and the parsed results must be added to these fields.</description></item><item><title>Apache Flink Table/SQL</title><link>/udf/apache-flink-table/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/apache-flink-table/index.html</guid><description>Introduction This is a User Defined Function for Apache Flink Table
Getting the UDF You can get the prebuilt UDF from maven central.
If you use a maven based project simply add this dependency to your project.
&lt;dependency> &lt;groupId>nl.basjes.parse.useragent&lt;/groupId> &lt;artifactId>yauaa-flink-table&lt;/artifactId> &lt;version>7.31.0&lt;/version> &lt;/dependency> Syntax Assume you register this function under the name ParseUserAgent Then the generic usage in your SQL is
ParseUserAgent(&lt;useragent>) This returns a Map&lt;String, String> with all the requested values in one go.</description></item><item><title>Apache Hive</title><link>/udf/apache-hive/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/apache-hive/index.html</guid><description>Introduction This is a User Defined Function for Apache Hive
Getting the UDF You can get the prebuilt UDF from maven central (yauaa-hive-7.31.0-udf.jar).
NOTE: You MUST use the -udf.jar: yauaa-hive-7.31.0-udf.jar
If you use a maven based project simply add this dependency
&lt;dependency> &lt;groupId>nl.basjes.parse.useragent&lt;/groupId> &lt;artifactId>yauaa-hive&lt;/artifactId> &lt;classifier>udf&lt;/classifier> &lt;version>7.31.0&lt;/version> &lt;/dependency> Building Simply install the normal build tools for a Java project (i.e. maven and jdk) and then simply do:
mvn clean package Example usage First the jar file must be ‘known’ Either by doing</description></item><item><title>Apache Nifi</title><link>/udf/apache-nifi/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/apache-nifi/index.html</guid><description>Introduction This is a User Defined Function for Apache Nifi
Introduction This is an Apache Nifi Processor for parsing User Agent Strings.
Getting the Processor You can get the prebuilt NAR file from maven central.
If you use a maven based project simply add this dependency
&lt;dependency> &lt;groupId>nl.basjes.parse.useragent&lt;/groupId> &lt;artifactId>yauaa-nifi&lt;/artifactId> &lt;type>nar&lt;/type> &lt;version>7.31.0&lt;/version> &lt;/dependency> Installation To install this function put the nar file in the &lt;nifi-path>/lib directory.
cp ./udfs/nifi/nifi-nar/target/yauaa-nifi-&lt;version>.nar &lt;nifi-path>/lib Make sure you replace &lt;nifi-path> with your actual path to your nifi installation. After you have added this nar file you will find the ParseUserAgent processor in the list.</description></item><item><title>Apache Pig</title><link>/udf/apache-pig/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/apache-pig/index.html</guid><description>DEPRECATED Apache Pig is no longer used. So with Yauaa 7 this UDF has been dropped. Version 6.12 is the last released version which still has the Apache Pig in it.
Introduction This is a User Defined Function for Apache Pig
Getting the UDF You can get the prebuilt UDF from maven central.
If you use a maven based project simply add this dependency
&lt;dependency> &lt;groupId>nl.basjes.parse.useragent&lt;/groupId> &lt;artifactId>yauaa-pig&lt;/artifactId> &lt;classifier>udf&lt;/classifier> &lt;version>6.12&lt;/version> &lt;/dependency> Example usage -- Import the UDF jar file so this script can use it REGISTER ../target/*-udf.jar; ------------------------------------------------------------------------ -- Define a more readable name for the UDF and pass optional parameters -- First parameter is ALWAYS the cache size (as a text string!) -- The parameters after that are the requested fields. ---------- -- If you simply want 'everything' -- DEFINE ParseUserAgent nl.basjes.parse.useragent.pig.ParseUserAgent; ---------- -- If you just want to set the cache -- DEFINE ParseUserAgent nl.basjes.parse.useragent.pig.ParseUserAgent('10000'); ---------- -- If you want to set the cache and only retrieve the specified fields DEFINE ParseUserAgent nl.basjes.parse.useragent.pig.ParseUserAgent('10000', 'DeviceClass', 'DeviceBrand' ); rawData = LOAD 'testcases.txt' USING PigStorage() AS ( useragent: chararray ); UaData = FOREACH rawData GENERATE useragent, -- Do NOT specify a type for this field as the UDF provides the definitions ParseUserAgent(useragent) AS parsedAgent;</description></item><item><title>Commandline usage</title><link>/udf/commandline/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/commandline/index.html</guid><description>Introduction With version 6.0 the dedicated commandline tool was removed.
Primary reason is that it was not getting any attention, and it did not perform well (mainly due to the relatively big startup overhead).
So if you have the need to use Yauaa from a commandline perspective the easiest way to do this is by starting the docker based webservlet locally (and leave it running “for a long time”) and use something like curl to get the information you are looking for.</description></item><item><title>Elastic LogStash</title><link>/udf/elastic-logstash/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/elastic-logstash/index.html</guid><description>Introduction User Defined Function (Filter plugin) for Elastic Logstash
STATUS: … DROPPED … With Yauaa 7.18.0 the logstash UDF has been dropped.
The primary reason is that 3 years after Elastic announced Java UDF support as “GA” they have not published the needed dependencies. The workaround I came up with is starting to cause more and more problems so I’m dropping it.
Still want it? Get the sources from the latest tag that still had it and build it yourself. https://github.com/nielsbasjes/yauaa/tree/v7.17.1/udfs/elastic/logstash</description></item><item><title>Elastic Search</title><link>/udf/elastic-search/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/elastic-search/index.html</guid><description>Introduction User Defined Function (ingest processor) for Elastic Search
STATUS: … EXPERIMENTAL … The ElasticSearch ingest plugin is very new.
And yes it is similar to https://www.elastic.co/guide/en/elasticsearch/reference/master/user-agent-processor.html
Getting the UDF Starting with 7.31.0 the prebuilt UDF is no longer distributed by me.
The ONLY reason for this change is that Elastic Search is VERY picky about the version of ES the Plugin was built for. If you have a Yauaa Plugin that was built against ES 8.17.1 then that plugin will not load in ES 8.17.2.</description></item><item><title>LogParser</title><link>/udf/logparser/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/logparser/index.html</guid><description>Introduction This is a User Defined Function for LogParser
Getting the UDF You can get the prebuilt UDF from maven central (yauaa-logparser-7.31.0-udf.jar).
NOTE: You MUST use the -udf.jar: yauaa-logparser-7.31.0-udf.jar
If you use a maven based project simply add this dependency
&lt;dependency> &lt;groupId>nl.basjes.parse.useragent&lt;/groupId> &lt;artifactId>yauaa-logparser&lt;/artifactId> &lt;classifier>udf&lt;/classifier> &lt;version>7.31.0&lt;/version> &lt;/dependency> Client hints Because the logparser can only dissect a single field into multiple pieces it is impossible to extend this to support User-Agent Client Hints.</description></item><item><title>Snowflake</title><link>/udf/snowflake/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/snowflake/index.html</guid><description>Introduction User Defined Function for Snowflake.
STATUS: … EXPERIMENTAL … The Snowflake UDF is very experimental for two reasons:
Snowflake has marked (last checked on 2021-11-07) Java based UDFs as a Preview Feature. I do not have Snowflake so I do not have any way of testing this other than getting feedback from you. Thanks to Luke Ambrosetti for helping out here!
See for more information:
https://docs.snowflake.com/en/developer-guide/udf/java/udf-java.html Installation and usage Download the UDF jar to the local file system and upload into a Snowflake internal or external stage.</description></item><item><title>Snowplow</title><link>/udf/snowplow/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/snowplow/index.html</guid><description>Introduction If you are a user of the Snowplow Analytics system and would like to use Yauaa in your analysis you are in luck.
The people at Snowplow have included Yauaa as a readily available feature in their system.
The official documentation: Snowplow Yauaa Enrichment</description></item><item><title>Trino</title><link>/udf/trino/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/udf/trino/index.html</guid><description>Introduction This is a User Defined Function for Trino (a.k.a. Presto SQL)
STATUS: … EXPERIMENTAL … The Trino plugin is very new. Please tell if it works or not in your case.
Trino now requires Java 23 (which is non-LTS) which is not readily available for installation in Ubuntu using a normal package manager. This means that I have chosen to no longer let the build fail if you do not have Java 22 installed. The CI build does do Java 23 so any breaking API changes should be detected there.</description></item></channel></rss>